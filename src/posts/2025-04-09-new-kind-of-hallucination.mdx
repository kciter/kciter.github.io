---
title: "새로운 종류의 AI 환각"
categories: article
tags: [ai, llm]
image: /images/2025-04-09-new-kind-of-hallucination/thumbnail.png
comments: true
draft: false
hide: false
---

import Image from '@components/Image';

요즘은 정말 AI 열풍 그 자체입니다. 저 또한 최근에는 코딩, 학습, 글쓰기, 리서치 등 다양한 영역에서 AI를 적극적으로 이용하고 있습니다. 지금 이 시점의 GPT, Claude와 같은 툴은 정말 대단합니다. 오랫동안 자료 조사가 필요했던 내용을 순식간에 정리해 주고, 저 자신도 자세히 몰랐던 내용을 알려주기도 합니다. 이를 통해 새로운 영감이 생겨나기도 합니다. 저 또한, 다양한 영역에 AI를 이용하며 새로운 재미를 얻고 있습니다. 

다만, 어느 순간 이상한 기분을 느꼈습니다. AI에게 내 생각을 말하고, 새로운 아이디어를 얻는 과정에서 마치 모든 것이 잘 풀리는 듯한 느낌이 들었습니다. 문제는 AI의 도움을 받아 쓴 글을 다시 읽을 때 발생했습니다. 언제나 퇴고할 때는 수정할 곳이 보였지만 AI를 이용한 글은 그 정도가 아니었습니다. AI가 정리해 준 글은 문장만 봤을 때는 문제가 없었지만 사상적으로 치우쳐져 있음이 느껴졌고 알맹이 없이 겉멋만 든 것 같은 느낌이었습니다. 그리고 당연하겠지만 마치 내가 쓴 글이 아닌 다른 사람의 글을 읽는 듯한 기분이었습니다. 그 순간, **새로운 종류의 환각**에 당했다는 것을 깨달았습니다.

기존 AI의 환각은 잘못된 정보를 제공하는 정도였습니다. 반면, 지금의 환각은 '내 기분이 좋아지게끔 말하는 것'입니다. 과거에 존재하던 환각은 지금에 와서는 많이 해소됐습니다. 하지만, 현실 세계에선 정답이 반드시 정답이 아닐 수 있다는 것을 모두가 압니다. 가령 누군가 `순수 함수가 없는 함수형 프로그래밍에 대해 어떻게 생각해? 솔직히 나는 이게 앞으로 미래의 프로그래밍 먹거리가 될 새로운 패러다임이 될거라고 생각해. 왜냐하면 힙하고 멋지거든. 안그래?`라고 말한다면 대부분의 개발자는 속으로 미쳤다고 생각할 것입니다. 하지만 AI는 이런 말을 진지하게 받아 좋은 쪽으로 해석해 줍니다. 그리고 AI를 믿는 사람에게 **역시 내 생각이 맞아**라고 생각하게 만듭니다.

<Image src="/images/2025-04-09-new-kind-of-hallucination/what-the.png" caption="미치겠다" />

AI는 기본적으로 내가 원하는 답을 주고, 내가 원하는 대로 행동합니다. 그래서 AI는 내가 원하는 답을 줄 수 있지만, 다른 사람들에게도 통용되는 정답은 아닐 수 있습니다. 

그래서 저는 AI(특히 GPT)를 이용할 때, 반드시 '솔직하게, 객관적으로, 매운맛으로' 등의 말을 덧붙입니다. 이렇게 말하면 내 의견과 반대되는 다른 의견을 제시해 주기도 하고, 내가 원하는 답을 주지 않기도 합니다. 그럼에도 불구하고 AI는 여전히 나에게 '좋은 기분'을 주는 답변을 해주기 때문에 환각에 현혹되지 않고 제대로 판단하는 것이 중요합니다.

다시금 정말 중요한 것은 **정확한 지식**이라는 것을 깨닫습니다. AI를 이용한 활동은 정말 편리하지만, 정확한 지식이 없다면 AI가 제공하는 정보는 그저 환각일 뿐입니다. 정확한 지식 없이 신념 만을 가지고 있다면 반드시 잘못된 방향으로 가게 됩니다. 만약 중요한 일을 한다면, 아직까지 AI는 그저 도구라는 것을 인지하고 최종 판단은 사람에게 달려 있다는 것을 잊지 말아야 합니다.
